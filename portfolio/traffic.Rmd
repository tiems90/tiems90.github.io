---
title: "Madrid - Real-time Traffic"
author: "Timo"
date: 4/15/2017
image: 'img/portfolio/mad.png'
output:
  blogdown::html_page:
    toc: true
    number_sections: true
    df_print: paged
description: "This workbook is mostly concerned with cleaning and analysing both real-time and historic traffic data in Madrid." 
---

#Load Data
Let's start with some open, real-time, Madrid traffic data!
First we load up our packages and download our data. Our real-time data can be downloaded through the link in our code on `datos.madrid.es`. The measured points are a bit further hidden away on the website. But can be accessed [here](http://datos.madrid.es/portal/site/egob/menuitem.c05c1f754a33a9fbe4b2e4b284f1a5a0/?vgnextoid=ee941ce6ba6d3410VgnVCM1000000b205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD), and downloaded as a zip file. 

```{r loading data, results='hide',message=FALSE, warning=FALSE}
#Data Loading
library(XML)
library(sp)
library(readr)
library(data.table)
library(spacetime)

#Data Wrangling & Analysis
library(tidyverse)
library(reshape2)
library(outliers)
library(corrplot)
library(lubridate)
library(dtplyr)

#Maps
library(rgdal)
library(tmap)
library(tmaptools)
library(leaflet)
library(OpenStreetMap)

#Load Data
traffic0 <- xmlToDataFrame('http://datos.madrid.es/egob/catalogo/202087-0-trafico-intensidad.xml') 
head(traffic0)
measured.points <- readOGR(dsn = path.expand("~/Documents/R/Git/data/data_madrid"), 'pmed_trafico')

#Set Parameters
proj <- '+proj=utm +zone=30 +ellps=intl +towgs84=-87,-98,-121,0,0,0,0 +units=m +no_defs'
pal <- get_brewer_pal('YlOrRd', 5, plot = FALSE)
```

#Data Cleaning
##Georreferencing
Now that we have loaded our packages and data, we find something interesting. The shapefile we loaded lacks a projection. Unfortunately the documentation does not specify the projection we need. After much googling, we wind up at the [Guía básica para el manejo de archivos Shapefile](http://datos.madrid.es/FWProjects/egob/contenidos/datasets/ficheros/Manejo%20básico%20de%20archivos%20shp.pdf) which allows us to set our proj4 string as the following:

`r proj`


```{r mapping data}
proj4string(measured.points) <- proj

madrid <- read_osm(measured.points, type = 'maptoolkit-topo')
tm_shape(madrid)+
  tm_raster()+
  tm_shape(measured.points)+
  tm_dots(col = 'blue')+
  tm_scale_bar()+
  tm_style_natural() +
  tm_layout(title = 'Measured Points in tmap')
```

However, to visualise this using a leaflet interactive plot we need to a different projection, namely `EPSG:4326`. 

```{r}
measured.points %>% 
  spTransform(CRS("+init=epsg:4326")) %>% 
  leaflet() %>% 
  addTiles() %>% 
  addPolygons(color = 'black',
              fill = 0.6,
              popup=measured.points$nombre)
```

  
##Data Cleaning
Some weird things are still in our data. These will need to be looked at before we do anything else. 
A few histograms already show us that some of the data is encoded as negative. They do not provide an explanation of this in the data, but it seems to occurr when we receive an error message. Therefore we will remove the sensors providing an error message. 

Let's start by renaming the columns so they make more sense and see what it looks like after we do that. 
```{r}
traffic <- traffic0 %>% 
  mutate(
    cars_hour = as.numeric(intensidad),
    control_pnt_full = as.numeric(ocupacion),
    load = as.numeric(carga),
    saturation = as.numeric(intensidadSat),
    avg_speed = as.numeric(velocidad)
  ) %>% 
  select(codigo, descripcion, cars_hour, control_pnt_full, load, saturation, avg_speed, error)

#Quick look at the data
head(traffic)
```

Here I spotted something strange. Cars/Hour takes a negative value at times. Let's explore this a bit further in a plot. 

```{r, echo=FALSE}
#Values below 0
hist(traffic$cars_hour, right = F, main = 'Values Below Zero')
```

It looks like we have quite a few of these. After looking around in the data it seems these errors occur in the instances that there is an error in the machine. So let's remove all the sensors who are giving error messages. 

``` {r}
#Remove non-functioning sensors. 
traffic <- traffic[!traffic$error=='0 0 0 0 0 0 0 0' &
                   !traffic$error=='S',]
```

And let's see if that fixed our problem!
```{r, echo=FALSE}
#After accounting for the erros in sensors, we no longer find any. 
hist(traffic$cars_hour, right = F, main = 'Values Below Zero')
```

The documentation also metions that in our measuring points data, there is a factor that indicates urban or interurban positions. Let's update these factor labels. 

```{r}
#current labels
levels(measured.points@data$tipo_elem)
#Let's update these. 
levels(measured.points@data$tipo_elem) <- c('Highway', 'City Roads')
```



##Merging

Now that we have our plotted data and the live data from Madrid, we can merge the two together into one SP dataframe.
The documentation, `PUNTOS MEDIDA TRAFICO_MADRID.pdf`, indicates that in our `traffic` the column `codigo` should coincide with `COD_CENT` in our georeferenced set. We can use this as a key to merge the two. 

```{r}
traffic.full <- merge(measured.points, traffic, 
                      by.x='cod_cent', by.y='codigo', 
                      duplicateGeoms = TRUE, all.x=F)
head(traffic.full@data)
```

#Exploratory Data Analysis

Let's have a look at our data now. Just to get a better idea of what we're working with. 
To make things easer on ourselves later, I only consider the cleaned data that merges well. 

##Missing Data

Let's see how many missing values we have. 

```{r}
df <- as.tbl(traffic.full@data)
sapply(df, function(y) sum(is.na(y)))
```

So we are missing descriptions, which shouldn't be too bad, since the name should be captured. We're missing a lot of values for speed, speed and saturation/description. We will later see that this is because only the highways have spedometers, and the saturation levels are only calculated for city roads. It is not too troubling, except for later when we look at correlations. We'll keep it in mind for the later excercises. 

##Distributions
Let's see how our data are distributed. 
```{r warning=FALSE}
df %>% 
  select(1, 7:11) %>% 
  melt("cod_cent") %>% 
  ggplot(aes(x=value))+
  geom_density(fill='grey')+
  facet_wrap(~variable, scales = 'free')
```

Key things to note here are the crazy outliers we have in cars per hour for some areas, and our other data. 
Perhaps these are a function of the road type? Let's have a look. 

```{r warning=FALSE}
df %>% 
  select(1,3, 7:11) %>% 
  melt(c("cod_cent", 'tipo_elem')) %>% 
  ggplot(aes(x=value,  group=tipo_elem, fill=tipo_elem))+
  geom_density(alpha=0.8)+
  facet_wrap(~variable, scales = 'free')
```

A first thing to note here is that the speed data is only available on the highway, whereas we find the saturation levels only on city roads. A quick check with our source documentation confirms this to be the case. 
However, It turns out it's a bit hard to see this due to all the outliers tampering with our tails in the distribution. Let's get rid of these first, and then recreate the graphs from above. To do this quickly, we use the `outliers` package. 

```{r}
df2 <- df
df2[,7:11] <- df[,7:11] %>% 
   rm.outlier(fill=TRUE, median=TRUE)

df2 %>% 
  select(1,3, 7:11) %>% 
  melt(c("cod_cent", 'tipo_elem')) %>% 
  ggplot(aes(x=value,  group=tipo_elem, fill=tipo_elem))+
  geom_density(alpha=0.8)+
  facet_wrap(~variable, scales = 'free')
```

There we go. A lot more informative. One key thing to notice immediately is that our city roads have much fewer cars per hour than our highways: which makes a lot of sense. We also see that they aren't used quite as heavily as the highway. 

I think we've done about all we can with the distributions. Let's have a look at the correlations in our data. 

##Correlations

Let's have a quick look at the correlations of the variables. 
Since two variables overlap, we'll make two charts. 
```{r}
#City Roads
df %>% 
  filter(tipo_elem == 'City Roads') %>% 
  select(7:10) %>% 
  cor(use='complete') %>% 
  corrplot('square')

#Highway
df %>% 
  filter(tipo_elem == 'Highway') %>% 
  select(7:11, -10) %>% 
  cor(use='complete') %>% 
  corrplot('square')
```

Our main conclusions here:

* Saturation and load are positively correlated with cars per hour. This makes sense, as these all measure how busy a given road is. 
* On highways, number of cars by the control point are also positively correlated with these. So is the average speed. This would suggest that as there's more traffic passing per hour, the average speed tends to be higher. (Although I'm sure that during traffic jams, this would look differently.)
* On city roads, it all tends to be a bit less strongly correlated. The exception being the load and cars at the control points. Strangly, Saturation appears to be slightly negatively correlated with load and control points being full. This is against expactations. 

#Maps{.tabset}

Now that we have joined, cleaned, and briefly analysed our data we can start looking at more interesting plots.
Let's start by finding out speedy roads. 

##Speed

We subset our dataset to the points we have speed data on and recreate our map. 

```{r}
speed <- subset(traffic.full, !is.na(avg_speed))
head(speed@data)

#Download a simpler map so it's easier to see for colourblind me. 
madrid.spd <- read_osm(speed, type = 'stamen-toner')

#Going to reverse the pallete here, so red can mean congested/slow
tm_shape(madrid.spd)+
  tm_raster()+
  tm_shape(speed)+
  tm_dots(col = 'avg_speed', palette= rev(pal),size = 0.2) + 
  tm_scale_bar() +
  tm_style_natural()
```

And now we can have a look at making a leaflet version of the same graph!

```{r}
pal_leaflet <- colorNumeric(
  palette = "inferno",
  domain = (speed$avg_speed))

popup <- paste(sep="","<b>", speed$nombre,"</b>",
                             "<br/>","<strong>","Average Speed: ","</strong>" ,speed$avg_speed, 'kmh',
                             "<br/>","<strong>","Cars per Hour: ","</strong>" ,speed$cars_hour)

speed %>% 
  spTransform(CRS("+init=epsg:4326")) %>% 
  leaflet() %>% 
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addPolygons(color = ~pal_leaflet(avg_speed),
              opacity = 1.0,
              fillOpacity = 0.5,
              popup=popup) %>%
  addLegend("bottomright", pal = pal_leaflet, values = ~avg_speed,
    title = "Average Speed",
    labFormat = labelFormat(suffix = " KMH"),
    opacity = 1
  )
```


##Congestion
Let's have a similar look at the most congested roads!

```{r}
saturation <- subset(traffic.full, !is.na(saturation))
head(saturation@data)

#Download a simpler map so it's easier to see for colourblind me. 
madrid.sat <- read_osm(saturation, type = 'stamen-toner')

tm_shape(madrid.sat)+
  tm_raster()+
  tm_shape(saturation)+
  tm_dots(col = 'saturation', palette=pal, size = 0.1) +
  tm_scale_bar()+
  tm_style_natural()
```

And to create it in leaflet...

```{r}
pal_leaflet <- colorNumeric(
  palette = "inferno",
  domain = saturation$saturation,
  reverse = T)

popup <- paste(sep="","<b>", saturation$nombre,"</b>",
                             "<br/>","<strong>","Saturation: ","</strong>" ,saturation$saturation,
                             "<br/>","<strong>","Cars per Hour: ","</strong>" ,saturation$cars_hour)

saturation %>% 
  spTransform(CRS("+init=epsg:4326")) %>% 
  leaflet() %>% 
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addPolygons(color = ~pal_leaflet(saturation),
              opacity = 1.0,
              fillOpacity = 0.5,
              popup=popup) %>%
  addLegend("bottomright", pal = pal_leaflet, values = ~(saturation),
    title = "Saturation",
    opacity = 1
  )
```

And that's all for now! :-) 

